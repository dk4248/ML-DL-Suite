{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.)\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"108pt\" height=\"276pt\"\n",
       " viewBox=\"0.00 0.00 108.00 276.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 272)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-272 104,-272 104,4 -4,4\"/>\n",
       "<!-- 2381438499920 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2381438499920</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77,-32 23,-32 23,0 77,0 77,-32\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-6.5\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 2381440928448 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2381440928448</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-88 6,-88 6,-68 94,-68 94,-88\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-74.5\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 2381440928448&#45;&gt;2381438499920 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2381440928448&#45;&gt;2381438499920</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-67.62C50,-61.1 50,-52.05 50,-43.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-43.65 50,-33.65 46.5,-43.65 53.5,-43.65\"/>\n",
       "</g>\n",
       "<!-- 2381438537248 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2381438537248</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-144 6,-144 6,-124 94,-124 94,-144\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-130.5\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 2381438537248&#45;&gt;2381440928448 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2381438537248&#45;&gt;2381440928448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-123.59C50,-117.01 50,-107.96 50,-99.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-99.81 50,-89.81 46.5,-99.81 53.5,-99.81\"/>\n",
       "</g>\n",
       "<!-- 2381431816736 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2381431816736</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-200 0,-200 0,-180 100,-180 100,-200\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-186.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2381431816736&#45;&gt;2381438537248 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2381431816736&#45;&gt;2381438537248</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-179.59C50,-173.01 50,-163.96 50,-155.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-155.81 50,-145.81 46.5,-155.81 53.5,-155.81\"/>\n",
       "</g>\n",
       "<!-- 2381438499600 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2381438499600</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77,-268 23,-268 23,-236 77,-236 77,-268\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-242.5\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 2381438499600&#45;&gt;2381431816736 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2381438499600&#45;&gt;2381431816736</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-235.55C50,-228.34 50,-219.66 50,-211.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-211.92 50,-201.92 46.5,-211.92 53.5,-211.92\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x22a783381d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the torch library\n",
    "import torch \n",
    "from torchviz import make_dot\n",
    "\n",
    "# Assign any value for x as tensor form\n",
    "# Set requires_grad=True So,\n",
    "# that autograd will record the operations\n",
    "x=torch.tensor(7.0,requires_grad=True)\n",
    "\n",
    "# Define the equation\n",
    "f = (x**2)+3\n",
    "\n",
    "# Differentiate using torch\n",
    "#Uses backward function to compute the gradient value\n",
    "f.backward()\n",
    "\n",
    "# Print the derivative value\n",
    "# of y i.e dy/dx = 2x = 2 X 7.0 = 14.\n",
    "print(x.grad)\n",
    "\n",
    "# Plot the computational graph\n",
    "make_dot(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 22.,  45.,  74.],\n",
      "        [109., 150., 197.],\n",
      "        [250., 309., 374.]])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"274pt\" height=\"500pt\"\n",
       " viewBox=\"0.00 0.00 274.00 500.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 496)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-496 270,-496 270,4 -4,4\"/>\n",
       "<!-- 2381329148944 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2381329148944</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"179,-32 125,-32 125,0 179,0 179,-32\"/>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-6.5\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 2381440929072 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2381440929072</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-88 108,-88 108,-68 196,-68 196,-88\"/>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-74.5\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 2381440929072&#45;&gt;2381329148944 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>2381440929072&#45;&gt;2381329148944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M152,-67.62C152,-61.1 152,-52.05 152,-43.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.5,-43.65 152,-33.65 148.5,-43.65 155.5,-43.65\"/>\n",
       "</g>\n",
       "<!-- 2381440933152 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2381440933152</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-144 108,-144 108,-124 196,-124 196,-144\"/>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-130.5\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 2381440933152&#45;&gt;2381440929072 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2381440933152&#45;&gt;2381440929072</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M152,-123.59C152,-117.01 152,-107.96 152,-99.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.5,-99.81 152,-89.81 148.5,-99.81 155.5,-99.81\"/>\n",
       "</g>\n",
       "<!-- 2381431515856 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2381431515856</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-200 108,-200 108,-180 196,-180 196,-200\"/>\n",
       "<text text-anchor=\"middle\" x=\"152\" y=\"-186.5\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 2381431515856&#45;&gt;2381440933152 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2381431515856&#45;&gt;2381440933152</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M152,-179.59C152,-173.01 152,-163.96 152,-155.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.5,-155.81 152,-145.81 148.5,-155.81 155.5,-155.81\"/>\n",
       "</g>\n",
       "<!-- 2381441257376 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2381441257376</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-256 72,-256 72,-236 160,-236 160,-256\"/>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-242.5\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 2381441257376&#45;&gt;2381431515856 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2381441257376&#45;&gt;2381431515856</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.27,-235.59C127.02,-228.47 133.7,-218.45 139.52,-209.72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.33,-211.82 144.96,-201.56 136.5,-207.94 142.33,-211.82\"/>\n",
       "</g>\n",
       "<!-- 2381441257808 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2381441257808</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"88,-368 0,-368 0,-348 88,-348 88,-368\"/>\n",
       "<text text-anchor=\"middle\" x=\"44\" y=\"-354.5\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 2381441257808&#45;&gt;2381441257376 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2381441257808&#45;&gt;2381441257376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M44.98,-347.91C46.77,-334.68 51.48,-309.75 63,-292 70.37,-280.64 81.45,-270.6 91.58,-262.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.53,-265.81 99.62,-257.15 89.45,-260.12 93.53,-265.81\"/>\n",
       "</g>\n",
       "<!-- 2381441258240 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2381441258240</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"200,-424 100,-424 100,-404 200,-404 200,-424\"/>\n",
       "<text text-anchor=\"middle\" x=\"150\" y=\"-410.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2381441258240&#45;&gt;2381441257808 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2381441258240&#45;&gt;2381441257808</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.54,-403.59C115.3,-395.32 91.39,-383.14 72.67,-373.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"74.46,-370.59 63.96,-369.17 71.28,-376.82 74.46,-370.59\"/>\n",
       "</g>\n",
       "<!-- 2381441258288 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>2381441258288</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"194,-368 106,-368 106,-348 194,-348 194,-368\"/>\n",
       "<text text-anchor=\"middle\" x=\"150\" y=\"-354.5\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 2381441258240&#45;&gt;2381441258288 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2381441258240&#45;&gt;2381441258288</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150,-403.59C150,-397.01 150,-387.96 150,-379.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"153.5,-379.81 150,-369.81 146.5,-379.81 153.5,-379.81\"/>\n",
       "</g>\n",
       "<!-- 2381441257664 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>2381441257664</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"266,-312 178,-312 178,-292 266,-292 266,-312\"/>\n",
       "<text text-anchor=\"middle\" x=\"222\" y=\"-298.5\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 2381441258240&#45;&gt;2381441257664 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>2381441258240&#45;&gt;2381441257664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M165.15,-403.73C177.08,-395.68 193.28,-382.99 203,-368 211.82,-354.41 216.65,-336.61 219.23,-323.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.62,-324.02 220.77,-313.58 215.71,-322.89 222.62,-324.02\"/>\n",
       "</g>\n",
       "<!-- 2381441300304 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>2381441300304</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"179,-492 121,-492 121,-460 179,-460 179,-492\"/>\n",
       "<text text-anchor=\"middle\" x=\"150\" y=\"-466.5\" font-family=\"monospace\" font-size=\"10.00\"> (3, 3)</text>\n",
       "</g>\n",
       "<!-- 2381441300304&#45;&gt;2381441258240 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2381441300304&#45;&gt;2381441258240</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150,-459.55C150,-452.34 150,-443.66 150,-435.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"153.5,-435.92 150,-425.92 146.5,-435.92 153.5,-435.92\"/>\n",
       "</g>\n",
       "<!-- 2381441258096 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>2381441258096</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-312 72,-312 72,-292 160,-292 160,-312\"/>\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-298.5\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 2381441258096&#45;&gt;2381441257376 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2381441258096&#45;&gt;2381441257376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M116,-291.59C116,-285.01 116,-275.96 116,-267.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-267.81 116,-257.81 112.5,-267.81 119.5,-267.81\"/>\n",
       "</g>\n",
       "<!-- 2381441258288&#45;&gt;2381441258096 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2381441258288&#45;&gt;2381441258096</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.08,-347.59C139.64,-340.55 133.42,-330.67 127.96,-322\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"130.95,-320.18 122.66,-313.58 125.03,-323.91 130.95,-320.18\"/>\n",
       "</g>\n",
       "<!-- 2381441257664&#45;&gt;2381431515856 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>2381441257664&#45;&gt;2381431515856</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M216.03,-291.62C204.56,-273.6 179.24,-233.81 164.11,-210.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.09,-208.19 158.77,-201.63 161.18,-211.95 167.09,-208.19\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x22a7241b500>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the library\n",
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Assign the input variable\n",
    "x = torch_input=torch.tensor([[1.0,2.0,3.0],\n",
    "\t\t\t\t\t\t\t[4.0,5.0,6.0],\n",
    "\t\t\t\t\t\t\t[7.0,8.0,9.0]],requires_grad=True)\n",
    "\n",
    "# define the function\n",
    "def f(x):\n",
    "\treturn (x**3) + 7*(x**2) + 5*x + 10\n",
    "\n",
    "# Assign the sum to another variable z\n",
    "z=f(x).sum()\n",
    "\n",
    "# Compute the gradient\n",
    "z.backward()\n",
    "\n",
    "# Find the gradient value\n",
    "print(x.grad)\n",
    "\n",
    "#Plot the computational graph\n",
    "make_dot(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of x: tensor([-0.3018])\n",
      "Gradient of b: tensor([1.])\n",
      "Gradient of w: tensor([0.6569])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"329pt\" height=\"288pt\"\n",
       " viewBox=\"0.00 0.00 329.00 288.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 284)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-284 325,-284 325,4 -4,4\"/>\n",
       "<!-- 2381441385728 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2381441385728</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"242,-32 188,-32 188,0 242,0 242,-32\"/>\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-6.5\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 2381441259440 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2381441259440</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"259,-88 171,-88 171,-68 259,-68 259,-88\"/>\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-74.5\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 2381441259440&#45;&gt;2381441385728 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2381441259440&#45;&gt;2381441385728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M215,-67.62C215,-61.1 215,-52.05 215,-43.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"218.5,-43.65 215,-33.65 211.5,-43.65 218.5,-43.65\"/>\n",
       "</g>\n",
       "<!-- 2381441257760 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2381441257760</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"203,-144 115,-144 115,-124 203,-124 203,-144\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-130.5\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 2381441257760&#45;&gt;2381441259440 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2381441257760&#45;&gt;2381441259440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168.75,-123.59C176.62,-116.01 187.9,-105.13 197.35,-96.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.5,-98.81 204.27,-89.35 194.64,-93.77 199.5,-98.81\"/>\n",
       "</g>\n",
       "<!-- 2381441260496 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2381441260496</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-206 0,-206 0,-186 100,-186 100,-206\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-192.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2381441260496&#45;&gt;2381441257760 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2381441260496&#45;&gt;2381441257760</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.03,-185.62C84.47,-176.03 111.83,-160.97 132.18,-149.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.69,-152.93 140.76,-145.04 130.31,-146.8 133.69,-152.93\"/>\n",
       "</g>\n",
       "<!-- 2381441300464 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2381441300464</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77,-280 23,-280 23,-248 77,-248 77,-280\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-254.5\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 2381441300464&#45;&gt;2381441260496 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2381441300464&#45;&gt;2381441260496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-247.69C50,-238.8 50,-227.46 50,-217.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-217.83 50,-207.83 46.5,-217.83 53.5,-217.83\"/>\n",
       "</g>\n",
       "<!-- 2381441258912 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2381441258912</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"218,-206 118,-206 118,-186 218,-186 218,-206\"/>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-192.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2381441258912&#45;&gt;2381441257760 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2381441258912&#45;&gt;2381441257760</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.59,-185.62C165.38,-177.56 163.6,-165.65 162.06,-155.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.54,-154.98 160.59,-145.61 158.61,-156.02 165.54,-154.98\"/>\n",
       "</g>\n",
       "<!-- 2381441297504 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2381441297504</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"195,-280 141,-280 141,-248 195,-248 195,-280\"/>\n",
       "<text text-anchor=\"middle\" x=\"168\" y=\"-254.5\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 2381441297504&#45;&gt;2381441258912 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2381441297504&#45;&gt;2381441258912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168,-247.69C168,-238.8 168,-227.46 168,-217.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.5,-217.83 168,-207.83 164.5,-217.83 171.5,-217.83\"/>\n",
       "</g>\n",
       "<!-- 2381441259776 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>2381441259776</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"321,-144 221,-144 221,-124 321,-124 321,-144\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-130.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2381441259776&#45;&gt;2381441259440 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2381441259776&#45;&gt;2381441259440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M261.25,-123.59C253.38,-116.01 242.1,-105.13 232.65,-96.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"235.36,-93.77 225.73,-89.35 230.5,-98.81 235.36,-93.77\"/>\n",
       "</g>\n",
       "<!-- 2381441297584 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>2381441297584</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"298,-212 244,-212 244,-180 298,-180 298,-212\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-186.5\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 2381441297584&#45;&gt;2381441259776 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2381441297584&#45;&gt;2381441259776</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271,-179.55C271,-172.34 271,-163.66 271,-155.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.5,-155.92 271,-145.92 267.5,-155.92 274.5,-155.92\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x22a78f5d190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the torch library\n",
    "import torch \n",
    "from torchviz import make_dot\n",
    "\n",
    "# Define Input variable\n",
    "x = torch.randn(1, requires_grad=True)\n",
    "w = torch.randn(1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# Define the graph structure\n",
    "# Forward pass\n",
    "y = w * x + b\n",
    "\n",
    "# Backward pass\n",
    "y.backward()\n",
    "\n",
    "#View the outputs\n",
    "print(\"Gradient of x:\", x.grad)\n",
    "print(\"Gradient of b:\", b.grad)\n",
    "print(\"Gradient of w:\", w.grad)\n",
    "\n",
    "# Update parameters\n",
    "w.data -= 0.01 * w.grad.data\n",
    "b.data -= 0.01 * b.grad.data\n",
    "\n",
    "# Plot the computational graph\n",
    "make_dot(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.layers = []\n",
    "\n",
    "    def cross_correlation(self, x, kernel, stride=1, padding=0):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        if not isinstance(kernel, torch.Tensor):\n",
    "            kernel = torch.tensor(kernel, dtype=torch.float32)\n",
    "        \n",
    "        if padding > 0:\n",
    "            x = torch.nn.functional.pad(x, (padding, padding, padding, padding))\n",
    "        \n",
    "        C, H, W = x.shape\n",
    "        KH, KW = kernel.shape\n",
    "        \n",
    "        output_H = (H - KH) // stride + 1\n",
    "        output_W = (W - KW) // stride + 1\n",
    "        \n",
    "        feature_map = torch.zeros((C, output_H, output_W))\n",
    "        \n",
    "        for c in range(C):\n",
    "            for i in range(0, output_H):\n",
    "                for j in range(0, output_W):\n",
    "                    feature_map[c, i, j] = torch.sum(\n",
    "                        x[c, i*stride:i*stride+KH, j*stride:j*stride+KW] * kernel[c]\n",
    "                    )\n",
    "        \n",
    "        return feature_map\n",
    "    \n",
    "    def pooling(self, feature_maps, stride, kernel_size, type=\"max\"):\n",
    "        if not isinstance(feature_maps, torch.Tensor):\n",
    "            feature_maps = torch.tensor(feature_maps, dtype=torch.float32)\n",
    "\n",
    "        C, H_fm, W_fm = feature_maps.shape\n",
    "        KH, KW = kernel_size\n",
    "\n",
    "        output_H = (H_fm - KH) // stride + 1\n",
    "        output_W = (W_fm - KW) // stride + 1\n",
    "\n",
    "        pooled_feature_maps = torch.zeros((C, output_H, output_W))\n",
    "\n",
    "        for i in range(C):\n",
    "            for j in range(output_H):\n",
    "                for k in range(output_W):\n",
    "                    if type == \"max\":\n",
    "                        pooled_feature_maps[i, j, k] = torch.max(\n",
    "                            feature_maps[i, j*stride:j*stride+KH, k*stride:k*stride+KW]\n",
    "                        )\n",
    "                    elif type == \"average\":\n",
    "                        pooled_feature_maps[i, j, k] = torch.mean(\n",
    "                            feature_maps[i, j*stride:j*stride+KH, k*stride:k*stride+KW]\n",
    "                        )\n",
    "\n",
    "        return pooled_feature_maps\n",
    "    \n",
    "    def add_layer(self, type, size, kernel_size = (3, 3), stride = 1, padding = 0, activation_function = 'Relu'):\n",
    "        if type == 'convolution':\n",
    "            layer = {\n",
    "                'type': 'convolution',\n",
    "                'size': size,\n",
    "                'kernel_size': kernel_size,\n",
    "                'stride': stride,\n",
    "                'padding': padding,\n",
    "                'activation_function': activation_function\n",
    "            }\n",
    "        elif type == 'pooling':\n",
    "            layer = {\n",
    "                'type': 'pooling',\n",
    "                'kernel_size': kernel_size,\n",
    "                'stride': stride\n",
    "            }\n",
    "        elif type == 'fully_connected':\n",
    "            layer = {\n",
    "                'type': 'fully_connected',\n",
    "                'size': size,\n",
    "                'activation_function': activation_function\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def train(self, X_train, Y_train, epochs = 1000, batch_size = 32, learning_rate = 0.01):\n",
    "        for epoch in range(epochs):\n",
    "            # shuffle the data\n",
    "            indices = torch.randperm(X_train.shape[0])\n",
    "            X_train = X_train[indices]\n",
    "            Y_train = Y_train[indices]\n",
    "\n",
    "            kernels = []\n",
    "            weights = []\n",
    "            biases = []\n",
    "            \n",
    "            for layer in self.layers:\n",
    "                layer_kernel = []\n",
    "                if layer['type'] == 'convolution':\n",
    "                    for i in range(layer['size']):\n",
    "                        kernel = torch.randn(layer['kernel_size'], requires_grad=True)\n",
    "                        layer_kernel.append(kernel)\n",
    "                    kernels.append(layer_kernel)\n",
    "\n",
    "            for i in range(0, X_train.shape[0], batch_size):\n",
    "                x = X_train[i:i+batch_size]\n",
    "                y = Y_train[i:i+batch_size]\n",
    "\n",
    "                for image in x:\n",
    "                    feature_maps = []\n",
    "\n",
    "                    for layer_kernel,layer in zip(kernels,self.layers):\n",
    "                        # now , layer_kernel is a list of kernels for each layer\n",
    "                        # and layer is a dictionary containing the layer information\n",
    "                        # now, for each layer if it is convolutional layer, we will make a feature map and apply cross correlation\n",
    "                        if layer['type'] == 'convolution':\n",
    "                            feature_map = []\n",
    "                            for kernel in layer_kernel:\n",
    "                                feature_map.append(self.cross_correlation(image, kernel, layer['stride'], layer['padding']))\n",
    "                            feature_maps.append(feature_map)\n",
    "                        elif layer['type'] == 'pooling':\n",
    "                            feature_maps = self.pooling(feature_maps[-1], layer['stride'], layer['kernel_size'])\n",
    "\n",
    "                    # now, we have the feature maps for the image\n",
    "\n",
    "                    # now, we will flatten the feature maps\n",
    "                    flattened_feature_maps = torch.flatten(feature_maps[-1])\n",
    "\n",
    "                    # now, we will apply the fully connected layers\n",
    "                    for layer in self.layers:\n",
    "                        if layer['type'] == 'fully_connected':\n",
    "                            weight = torch.randn(layer['size'], requires_grad=True)\n",
    "                            bias = torch.randn(1, requires_grad=True)\n",
    "\n",
    "                            \n",
    "\n",
    "\n",
    "                        \n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.layers = []\n",
    "\n",
    "    def cross_correlation(self, x, kernel, stride=1, padding=0):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        if not isinstance(kernel, torch.Tensor):\n",
    "            kernel = torch.tensor(kernel, dtype=torch.float32)\n",
    "        \n",
    "        if padding > 0:\n",
    "            x = torch.nn.functional.pad(x, (padding, padding, padding, padding))\n",
    "        \n",
    "        C, H, W = x.shape\n",
    "        KH, KW = kernel.shape\n",
    "        \n",
    "        output_H = (H - KH) // stride + 1\n",
    "        output_W = (W - KW) // stride + 1\n",
    "        \n",
    "        feature_map = torch.zeros((C, output_H, output_W))\n",
    "        \n",
    "        for c in range(C):\n",
    "            for i in range(0, output_H):\n",
    "                for j in range(0, output_W):\n",
    "                    feature_map[c, i, j] = torch.sum(\n",
    "                        x[c, i*stride:i*stride+KH, j*stride:j*stride+KW] * kernel[c]\n",
    "                    )\n",
    "        \n",
    "        return feature_map\n",
    "    \n",
    "    def pooling(self, feature_maps, stride, kernel_size, type=\"max\"):\n",
    "        if not isinstance(feature_maps, torch.Tensor):\n",
    "            feature_maps = torch.tensor(feature_maps, dtype=torch.float32)\n",
    "\n",
    "        C, H_fm, W_fm = feature_maps.shape\n",
    "        KH, KW = kernel_size\n",
    "\n",
    "        output_H = (H_fm - KH) // stride + 1\n",
    "        output_W = (W_fm - KW) // stride + 1\n",
    "\n",
    "        pooled_feature_maps = torch.zeros((C, output_H, output_W))\n",
    "\n",
    "        for i in range(C):\n",
    "            for j in range(output_H):\n",
    "                for k in range(output_W):\n",
    "                    if type == \"max\":\n",
    "                        pooled_feature_maps[i, j, k] = torch.max(\n",
    "                            feature_maps[i, j*stride:j*stride+KH, k*stride:k*stride+KW]\n",
    "                        )\n",
    "                    elif type == \"average\":\n",
    "                        pooled_feature_maps[i, j, k] = torch.mean(\n",
    "                            feature_maps[i, j*stride:j*stride+KH, k*stride:k*stride+KW]\n",
    "                        )\n",
    "\n",
    "        return pooled_feature_maps\n",
    "    \n",
    "    def add_layer(self, type, size = 1, kernel_size = (3, 3), stride = 1, padding = 0, activation_function = 'Relu'):\n",
    "        if type == 'convolution':\n",
    "            layer = {\n",
    "                'type': 'convolution',\n",
    "                'size': size,\n",
    "                'kernel_size': kernel_size,\n",
    "                'stride': stride,\n",
    "                'padding': padding,\n",
    "                'activation_function': activation_function\n",
    "            }\n",
    "        elif type == 'pooling':\n",
    "            layer = {\n",
    "                'type': 'pooling',\n",
    "                'kernel_size': kernel_size,\n",
    "                'stride': stride\n",
    "            }\n",
    "        elif type == 'fully_connected':\n",
    "            layer = {\n",
    "                'type': 'fully_connected',\n",
    "                'size': size,\n",
    "                'activation_function': activation_function\n",
    "            }\n",
    "\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def train(self, X_train, Y_train, epochs = 10, batch_size = 32, learning_rate = 0.01):\n",
    "        kernels = []\n",
    "        fc_layers = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "            if layer['type'] == 'convolution':\n",
    "                layer_kernel = [torch.randn(layer['kernel_size'], requires_grad=True) for _ in range(layer['size'])]\n",
    "                kernels.append(layer_kernel)\n",
    "            elif layer['type'] == 'fully_connected':\n",
    "                fc_weight = torch.randn(layer['size'], requires_grad=True)\n",
    "                fc_bias = torch.randn(layer['size'], requires_grad=True)\n",
    "                fc_layers.append((fc_weight, fc_bias))\n",
    "\n",
    "        optimizer = torch.optim.SGD([{'params': kernel} for layer_kernel in kernels for kernel in layer_kernel] +\n",
    "                                    [{'params': param} for fc_weight, fc_bias in fc_layers for param in [fc_weight, fc_bias]], lr=learning_rate)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for i in range(0, X_train.shape[0], batch_size):\n",
    "                x_batch = X_train[i:i+batch_size]\n",
    "                y_batch = Y_train[i:i+batch_size]\n",
    "\n",
    "                batch_loss = 0\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                for image, label in zip(x_batch, y_batch):\n",
    "                    feature_maps = [image]\n",
    "\n",
    "                    for layer, layer_kernel in zip(self.layers, kernels):\n",
    "                        if layer['type'] == 'convolution':\n",
    "                            new_feature_maps = []\n",
    "                            for kernel in layer_kernel:\n",
    "                                new_feature_maps.append(self.cross_correlation(feature_maps[-1], kernel, layer['stride'], layer['padding']))\n",
    "                            feature_maps.append(torch.stack(new_feature_maps))\n",
    "                        elif layer['type'] == 'pooling':\n",
    "                            feature_maps.append(self.pooling(feature_maps[-1], layer['stride'], layer['kernel_size']))\n",
    "\n",
    "                    flattened_feature_maps = feature_maps[-1].view(-1)\n",
    "\n",
    "                    output = flattened_feature_maps\n",
    "                    for fc_weight, fc_bias in fc_layers:\n",
    "                        output = torch.matmul(output, fc_weight) + fc_bias\n",
    "                        if layer.get('activation_function', None) == 'Relu':\n",
    "                            output = F.relu(output)\n",
    "\n",
    "                    loss = F.cross_entropy(output.view(1, -1), label.view(1))\n",
    "                    batch_loss += loss\n",
    "\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "                make_dot(batch_loss).render(f'batch_loss_{i}')\n",
    "\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(X_train)}')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            feature_maps = [X]\n",
    "            for layer, layer_kernel in zip(self.layers, kernels):\n",
    "                if layer['type'] == 'convolution':\n",
    "                    new_feature_maps = []\n",
    "                    for kernel in layer_kernel:\n",
    "                        new_feature_maps.append(self.cross_correlation(feature_maps[-1], kernel, layer['stride'], layer['padding']))\n",
    "                    feature_maps.append(torch.stack(new_feature_maps))\n",
    "                elif layer['type'] == 'pooling':\n",
    "                    feature_maps.append(self.pooling(feature_maps[-1], layer['stride'], layer['kernel_size']))\n",
    "\n",
    "            flattened_feature_maps = feature_maps[-1].view(-1)\n",
    "\n",
    "            output = flattened_feature_maps\n",
    "            for fc_weight, fc_bias in fc_layers:\n",
    "                output = torch.matmul(output, fc_weight) + fc_bias\n",
    "                if layer.get('activation_function', None) == 'Relu':\n",
    "                    output = F.relu(output)\n",
    "\n",
    "            return torch.argmax(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CNN' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39madd_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfully_connected\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CNN' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "num_classes = 10  # MNIST has 10 classes\n",
    "model = CNN(num_classes)\n",
    "model.add_layer('convolution', size=32, kernel_size=(3, 3), stride=1, padding=1)\n",
    "model.add_layer('pooling', kernel_size=(2, 2), stride=2)\n",
    "model.add_layer('convolution', size=64, kernel_size=(3, 3), stride=1, padding=1)\n",
    "model.add_layer('pooling', kernel_size=(2, 2), stride=2)\n",
    "model.add_layer('fully_connected', size=128, activation_function='Relu')\n",
    "model.add_layer('fully_connected', size=10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    print('Training complete')\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "validate_model(model, val_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From local helper files\n",
    "from helper_evaluation import set_all_seeds, set_deterministic, compute_confusion_matrix\n",
    "from helper_train import train_model\n",
    "from helper_plotting import plot_training_loss, plot_accuracy, show_examples, plot_confusion_matrix\n",
    "from helper_dataset import get_dataloaders_cifar10, UnNormalize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
